<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<meta name="generator" content="hevea 2.09">
<link rel="stylesheet" type="text/css" href="thinkpython2.css">
<title>Case study: data structure selection</title>
</head>
<body>
<a href="thinkpython2013.html"><img src="back.png" ALT="Previous"></a>
<a href="index.html.1"><img src="up.png" ALT="Up"></a>
<a href="thinkpython2015.html"><img src="next.png" ALT="Next"></a>
<hr>
<table>

<tr>

<td valign="top" width="100" bgcolor="#b6459a">
</td>

<td valign="top" width="600" style="padding: 20px 20px;">

<p>
<a href="http://amzn.to/1VUYQUU">Buy this book at Amazon.com</a>

<h1 class="chapter" id="sec151">Chapter&#XA0;13&#XA0;&#XA0;Case study: data structure selection</h1>
<p>At this point you have learned about Python&#X2019;s core data structures,
and you have seen some of the algorithms that use them.
If you would like to know more about algorithms, this might be a good
time to read Chapter&#XA0;<a href="thinkpython2022.html#algorithms">B</a>.
But you don&#X2019;t have to read it before you go on; you can read
it whenever you are interested.</p><p>This chapter presents a case study with exercises that let
you think about choosing data structures and practice using them.</p>
<h2 class="section" id="sec152">13.1&#XA0;&#XA0;Word frequency analysis</h2>
<p>
<a id="analysis"></a></p><p>As usual, you should at least attempt the exercises
before you read my solutions.</p><div class="theorem"><span class="c010">Exercise&#XA0;1</span>&#XA0;&#XA0;<p><em>Write a program that reads a file, breaks each line into
words, strips whitespace and punctuation from the words, and
converts them to lowercase.
</em><a id="hevea_default1132"></a>
<a id="hevea_default1133"></a></p><p><em>Hint: The <span class="c004">string</span> module provides a string named <span class="c004">whitespace</span>,
which contains space, tab, newline, etc., and <span class="c004">punctuation</span> which contains the punctuation characters. Let&#X2019;s see
if we can make Python swear:</em></p><pre class="verbatim"><em>&gt;&gt;&gt; import string
&gt;&gt;&gt; string.punctuation
'!"#$%&amp;'()*+,-./:;&lt;=&gt;?@[\]^_`{|}~'
</em></pre><p><em>Also, you might consider using the string methods <span class="c004">strip</span>,
<span class="c004">replace</span> and <span class="c004">translate</span>.
</em><a id="hevea_default1134"></a>
<a id="hevea_default1135"></a>
<a id="hevea_default1136"></a>
<a id="hevea_default1137"></a>
<a id="hevea_default1138"></a>
<a id="hevea_default1139"></a></p></div><div class="theorem"><span class="c010">Exercise&#XA0;2</span>&#XA0;&#XA0;
<a id="hevea_default1140"></a><p><em>Go to Project Gutenberg (</em><a href="http://gutenberg.org"><span class="c004"><em>http://gutenberg.org</em></span></a><em>) and download 
your favorite out-of-copyright book in plain text format.
</em><a id="hevea_default1141"></a>
<a id="hevea_default1142"></a></p><p><em>Modify your program from the previous exercise to read the book
you downloaded, skip over the header information at the beginning
of the file, and process the rest of the words as before.</em></p><p><em>Then modify the program to count the total number of words in
the book, and the number of times each word is used.
</em><a id="hevea_default1143"></a>
<a id="hevea_default1144"></a></p><p><em>Print the number of different words used in the book. Compare
different books by different authors, written in different eras.
Which author uses the most extensive vocabulary?
</em></p></div><div class="theorem"><span class="c010">Exercise&#XA0;3</span>&#XA0;&#XA0;<p><em>Modify the program from the previous exercise to print the
20 most frequently used words in the book.</em></p></div><div class="theorem"><span class="c010">Exercise&#XA0;4</span>&#XA0;&#XA0;<p><em>Modify the previous program to read a word list (see
Section&#XA0;</em><a href="thinkpython2010.html#wordlist"><em>9.1</em></a><em>) and then print all the words in the book that
are not in the word list. How many of them are typos? How many of
them are common words that </em>should<em> be in the word list, and how
many of them are really obscure?</em></p></div>
<h2 class="section" id="sec153">13.2&#XA0;&#XA0;Random numbers</h2>
<p>
<a id="hevea_default1145"></a>
<a id="hevea_default1146"></a>
<a id="hevea_default1147"></a>
<a id="hevea_default1148"></a></p><p>Given the same inputs, most computer programs generate the same
outputs every time, so they are said to be <span class="c010">deterministic</span>.
Determinism is usually a good thing, since we expect the same
calculation to yield the same result. For some applications, though,
we want the computer to be unpredictable. Games are an obvious
example, but there are more.</p><p>Making a program truly nondeterministic turns out to be difficult,
but there are ways to make it at least seem nondeterministic. One of
them is to use algorithms that generate <span class="c010">pseudorandom</span> numbers.
Pseudorandom numbers are not truly random because they are generated
by a deterministic computation, but just by looking at the numbers it
is all but impossible to distinguish them from random.
<a id="hevea_default1149"></a>
<a id="hevea_default1150"></a></p><p>The <span class="c004">random</span> module provides functions that generate
pseudorandom numbers (which I will simply call &#X201C;random&#X201D; from
here on).
<a id="hevea_default1151"></a>
<a id="hevea_default1152"></a></p><p>The function <span class="c004">random</span> returns a random float
between 0.0 and 1.0 (including 0.0 but not 1.0). Each time you
call <span class="c004">random</span>, you get the next number in a long series. To see a
sample, run this loop:</p><pre class="verbatim">import random

for i in range(10):
    x = random.random()
    print(x)
</pre><p>The function <span class="c004">randint</span> takes parameters <span class="c004">low</span> and
<span class="c004">high</span> and returns an integer between <span class="c004">low</span> and
<span class="c004">high</span> (including both).
<a id="hevea_default1153"></a>
<a id="hevea_default1154"></a></p><pre class="verbatim">&gt;&gt;&gt; random.randint(5, 10)
5
&gt;&gt;&gt; random.randint(5, 10)
9
</pre><p>To choose an element from a sequence at random, you can use
<span class="c004">choice</span>:
<a id="hevea_default1155"></a>
<a id="hevea_default1156"></a></p><pre class="verbatim">&gt;&gt;&gt; t = [1, 2, 3]
&gt;&gt;&gt; random.choice(t)
2
&gt;&gt;&gt; random.choice(t)
3
</pre><p>The <span class="c004">random</span> module also provides functions to generate
random values from continuous distributions including
Gaussian, exponential, gamma, and a few more.</p><div class="theorem"><span class="c010">Exercise&#XA0;5</span>&#XA0;&#XA0;
<a id="hevea_default1157"></a><p><em>Write a function named <code>choose_from_hist</code> that takes
a histogram as defined in Section&#XA0;</em><a href="thinkpython2012.html#histogram"><em>11.2</em></a><em> and returns a 
random value from the histogram, chosen with probability
in proportion to frequency. For example, for this histogram:</em></p><pre class="verbatim"><em>&gt;&gt;&gt; t = ['a', 'a', 'b']
&gt;&gt;&gt; hist = histogram(t)
&gt;&gt;&gt; hist
{'a': 2, 'b': 1}
</em></pre><p><em>your function should return <code>'a'</code> with probability </em>2/3<em> and <code>'b'</code>
with probability </em>1/3<em>.
</em></p></div>
<h2 class="section" id="sec154">13.3&#XA0;&#XA0;Word histogram</h2>
<p>You should attempt the previous exercises before you go on.
You can download my solution from
<a href="http://thinkpython2.com/code/analyze_book1.py"><span class="c004">http://thinkpython2.com/code/analyze_book1.py</span></a>. You will
also need <a href="http://thinkpython2.com/code/emma.txt"><span class="c004">http://thinkpython2.com/code/emma.txt</span></a>.</p><p>Here is a program that reads a file and builds a histogram of the
words in the file:
<a id="hevea_default1158"></a></p><pre class="verbatim">import string

def process_file(filename):
    hist = dict()
    fp = open(filename)
    for line in fp:
        process_line(line, hist)
    return hist

def process_line(line, hist):
    line = line.replace('-', ' ')
    
    for word in line.split():
        word = word.strip(string.punctuation + string.whitespace)
        word = word.lower()
        hist[word] = hist.get(word, 0) + 1

hist = process_file('emma.txt')
</pre><p>This program reads <span class="c004">emma.txt</span>, which contains the text of <em>Emma</em> by Jane Austen.
<a id="hevea_default1159"></a></p><p><code>process_file</code> loops through the lines of the file,
passing them one at a time to <code>process_line</code>. The histogram
<span class="c004">hist</span> is being used as an accumulator.
<a id="hevea_default1160"></a>
<a id="hevea_default1161"></a></p><p><code>process_line</code> uses the string method <span class="c004">replace</span> to replace
hyphens with spaces before using <span class="c004">split</span> to break the line into a
list of strings. It traverses the list of words and uses <span class="c004">strip</span>
and <span class="c004">lower</span> to remove punctuation and convert to lower case. (It
is a shorthand to say that strings are &#X201C;converted&#X201D;; remember that
strings are immutable, so methods like <span class="c004">strip</span> and <span class="c004">lower</span>
return new strings.)</p><p>Finally, <code>process_line</code> updates the histogram by creating a new
item or incrementing an existing one.
<a id="hevea_default1162"></a></p><p>To count the total number of words in the file, we can add up
the frequencies in the histogram:</p><pre class="verbatim">def total_words(hist):
    return sum(hist.values())
</pre><p>The number of different words is just the number of items in
the dictionary:</p><pre class="verbatim">def different_words(hist):
    return len(hist)
</pre><p>Here is some code to print the results:</p><pre class="verbatim">print('Total number of words:', total_words(hist))
print('Number of different words:', different_words(hist))
</pre><p>And the results:</p><pre class="verbatim">Total number of words: 161080
Number of different words: 7214
</pre>
<h2 class="section" id="sec155">13.4&#XA0;&#XA0;Most common words</h2>
<p>To find the most common words, we can make a list of tuples,
where each tuple contains a word and its frequency,
and sort it.</p><p>The following function takes a histogram and returns a list of
word-frequency tuples:</p><pre class="verbatim">def most_common(hist):
    t = []
    for key, value in hist.items():
        t.append((value, key))

    t.sort(reverse=True)
    return t
</pre><p>In each tuple, the frequency appears first, so the resulting list is
sorted by frequency. Here is a loop that prints the ten most common
words:</p><pre class="verbatim">t = most_common(hist)
print('The most common words are:')
for freq, word in t[:10]:
    print(word, freq, sep='\t')
</pre><p>I use the keyword argument <span class="c004">sep</span> to tell <span class="c004">print</span> to use a tab
character as a &#X201C;separator&#X201D;, rather than a space, so the second
column is lined up. Here are the results from <em>Emma</em>:</p><pre class="verbatim">The most common words are:
to      5242
the     5205
and     4897
of      4295
i       3191
a       3130
it      2529
her     2483
was     2400
she     2364
</pre><p>This code can be simplified using the <span class="c004">key</span> parameter of
the <span class="c004">sort</span> function. If you are curious, you can read about it
at <a href="https://wiki.python.org/moin/HowTo/Sorting"><span class="c004">https://wiki.python.org/moin/HowTo/Sorting</span></a>.</p>
<h2 class="section" id="sec156">13.5&#XA0;&#XA0;Optional parameters</h2>
<p>
<a id="hevea_default1163"></a>
<a id="hevea_default1164"></a></p><p>We have seen built-in functions and methods that take optional
arguments. It is possible to write programmer-defined functions
with optional arguments, too. For example, here is a function that
prints the most common words in a histogram
<a id="hevea_default1165"></a>
<a id="hevea_default1166"></a></p><pre class="verbatim">def print_most_common(hist, num=10):
    t = most_common(hist)
    print('The most common words are:')
    for freq, word in t[:num]:
        print(word, freq, sep='\t')
</pre><p>The first parameter is required; the second is optional.
The <span class="c010">default value</span> of <span class="c004">num</span> is 10.
<a id="hevea_default1167"></a>
<a id="hevea_default1168"></a></p><p>If you only provide one argument:</p><pre class="verbatim">print_most_common(hist)
</pre><p><span class="c004">num</span> gets the default value. If you provide two arguments:</p><pre class="verbatim">print_most_common(hist, 20)
</pre><p><span class="c004">num</span> gets the value of the argument instead. In other
words, the optional argument <span class="c010">overrides</span> the default value.
<a id="hevea_default1169"></a></p><p>If a function has both required and optional parameters, all
the required parameters have to come first, followed by the
optional ones.</p>
<h2 class="section" id="sec157">13.6&#XA0;&#XA0;Dictionary subtraction</h2>
<p>
<a id="dictsub"></a>
<a id="hevea_default1170"></a>
<a id="hevea_default1171"></a></p><p>Finding the words from the book that are not in the word list
from <span class="c004">words.txt</span> is a problem you might recognize as set
subtraction; that is, we want to find all the words from one
set (the words in the book) that are not in the other (the
words in the list).</p><p><span class="c004">subtract</span> takes dictionaries <span class="c004">d1</span> and <span class="c004">d2</span> and returns a
new dictionary that contains all the keys from <span class="c004">d1</span> that are not
in <span class="c004">d2</span>. Since we don&#X2019;t really care about the values, we
set them all to None.</p><pre class="verbatim">def subtract(d1, d2):
    res = dict()
    for key in d1:
        if key not in d2:
            res[key] = None
    return res
</pre><p>To find the words in the book that are not in <span class="c004">words.txt</span>,
we can use <code>process_file</code> to build a histogram for
<span class="c004">words.txt</span>, and then subtract:</p><pre class="verbatim">words = process_file('words.txt')
diff = subtract(hist, words)

print("Words in the book that aren't in the word list:")
for word in diff:
    print(word, end=' ')
</pre><p>Here are some of the results from <em>Emma</em>:</p><pre class="verbatim">Words in the book that aren't in the word list:
rencontre jane's blanche woodhouses disingenuousness 
friend's venice apartment ...
</pre><p>Some of these words are names and possessives. Others, like
&#X201C;rencontre&#X201D;, are no longer in common use. But a few are common
words that should really be in the list!</p><div class="theorem"><span class="c010">Exercise&#XA0;6</span>&#XA0;&#XA0;
<a id="hevea_default1172"></a>
<a id="hevea_default1173"></a><p><em>Python provides a data structure called <span class="c004">set</span> that provides many
common set operations. You can read about them in Section&#XA0;</em><a href="thinkpython2020.html#sets"><em>19.5</em></a><em>,
or read the documentation at
</em><a href="http://docs.python.org/3/library/stdtypes.html#types-set"><span class="c004"><em>http://docs.python.org/3/library/stdtypes.html#types-set</em></span></a><em>.</em></p><p><em>Write a program that uses set subtraction to find words in the book
that are not in the word list. Solution:
</em><a href="http://thinkpython2.com/code/analyze_book2.py"><em><span class="c004">http://thinkpython2.com/code/analyze_book2.py</span></em></a><em>.</em></p></div>
<h2 class="section" id="sec158">13.7&#XA0;&#XA0;Random words</h2>
<p>
<a id="randomwords"></a>
<a id="hevea_default1174"></a></p><p>To choose a random word from the histogram, the simplest algorithm
is to build a list with multiple copies of each word, according
to the observed frequency, and then choose from the list:</p><pre class="verbatim">def random_word(h):
    t = []
    for word, freq in h.items():
        t.extend([word] * freq)

    return random.choice(t)
</pre><p>The expression <span class="c004">[word] * freq</span> creates a list with <span class="c004">freq</span>
copies of the string <span class="c004">word</span>. The <span class="c004">extend</span>
method is similar to <span class="c004">append</span> except that the argument is
a sequence.</p><p>This algorithm works, but it is not very efficient; each time you
choose a random word, it rebuilds the list, which is as big as
the original book. An obvious improvement is to build the list
once and then make multiple selections, but the list is still big.</p><p>An alternative is:</p><ol class="enumerate" type=1><li class="li-enumerate">Use <span class="c004">keys</span> to get a list of the words in the book.</li><li class="li-enumerate">Build a list that contains the cumulative sum of the word
frequencies (see Exercise&#XA0;<a href="thinkpython2011.html#cumulative">2</a>). The last item
in this list is the total number of words in the book, <span class="c009">n</span>.</li><li class="li-enumerate">Choose a random number from 1 to <span class="c009">n</span>. Use a bisection search
(See Exercise&#XA0;<a href="thinkpython2011.html#bisection">10</a>) to find the index where the random
number would be inserted in the cumulative sum.</li><li class="li-enumerate">Use the index to find the corresponding word in the word list.</li></ol><div class="theorem"><span class="c010">Exercise&#XA0;7</span>&#XA0;&#XA0;
<a id="randhist"></a>
<a id="hevea_default1175"></a><p><em>Write a program that uses this algorithm to choose a random word from
the book. Solution:
</em><a href="http://thinkpython2.com/code/analyze_book3.py"><em><span class="c004">http://thinkpython2.com/code/analyze_book3.py</span></em></a><em>.</em></p></div>
<h2 class="section" id="sec159">13.8&#XA0;&#XA0;Markov analysis</h2>
<p>
<a id="markov"></a>
<a id="hevea_default1176"></a></p><p>If you choose words from the book at random, you can get a
sense of the vocabulary, but you probably won&#X2019;t get a sentence:</p><pre class="verbatim">this the small regard harriet which knightley's it most things
</pre><p>A series of random words seldom makes sense because there
is no relationship between successive words. For example, in
a real sentence you would expect an article like &#X201C;the&#X201D; to
be followed by an adjective or a noun, and probably not a verb
or adverb.</p><p>One way to measure these kinds of relationships is Markov
analysis, which
characterizes, for a given sequence of words, the probability of the
words that might come next. For example, the song <em>Eric, the Half a
Bee</em> begins:</p><blockquote class="quote">
Half a bee, philosophically, <br>
Must, ipso facto, half not be. <br>
But half the bee has got to be <br>
Vis a vis, its entity. D&#X2019;you see? <br>
<br>
But can a bee be said to be <br>
Or not to be an entire bee <br>
When half the bee is not a bee <br>
Due to some ancient injury? <br>
</blockquote><p>
In this text,
the phrase &#X201C;half the&#X201D; is always followed by the word &#X201C;bee&#X201D;,
but the phrase &#X201C;the bee&#X201D; might be followed by either
&#X201C;has&#X201D; or &#X201C;is&#X201D;.
<a id="hevea_default1177"></a>
<a id="hevea_default1178"></a>
<a id="hevea_default1179"></a></p><p>The result of Markov analysis is a mapping from each prefix
(like &#X201C;half the&#X201D; and &#X201C;the bee&#X201D;) to all possible suffixes
(like &#X201C;has&#X201D; and &#X201C;is&#X201D;).
<a id="hevea_default1180"></a>
<a id="hevea_default1181"></a></p><p>Given this mapping, you can generate a random text by
starting with any prefix and choosing at random from the
possible suffixes. Next, you can combine the end of the
prefix and the new suffix to form the next prefix, and repeat.</p><p>For example, if you start with the prefix &#X201C;Half a&#X201D;, then the
next word has to be &#X201C;bee&#X201D;, because the prefix only appears
once in the text. The next prefix is &#X201C;a bee&#X201D;, so the
next suffix might be &#X201C;philosophically&#X201D;, &#X201C;be&#X201D; or &#X201C;due&#X201D;.</p><p>In this example the length of the prefix is always two, but
you can do Markov analysis with any prefix length.</p><div class="theorem"><span class="c010">Exercise&#XA0;8</span>&#XA0;&#XA0;<p><em>Markov analysis:</em></p><ol class="enumerate" type=1><li class="li-enumerate"><em>Write a program to read a text from a file and perform Markov
analysis. The result should be a dictionary that maps from
prefixes to a collection of possible suffixes. The collection
might be a list, tuple, or dictionary; it is up to you to make
an appropriate choice. You can test your program with prefix
length two, but you should write the program in a way that makes
it easy to try other lengths.</em></li><li class="li-enumerate"><em>Add a function to the previous program to generate random text
based on the Markov analysis. Here is an example from </em>Emma<em>
with prefix length 2:</em><blockquote class="quote"><em>
He was very clever, be it sweetness or be angry, ashamed or only
amused, at such a stroke. She had never thought of Hannah till you
were never meant for me?" "I cannot make speeches, Emma:" he soon cut
it all himself.
</em></blockquote><p><em>For this example, I left the punctuation attached to the words.
The result is almost syntactically correct, but not quite.
Semantically, it almost makes sense, but not quite.</em></p><p><em>What happens if you increase the prefix length? Does the random
text make more sense?</em></p></li><li class="li-enumerate"><em>Once your program is working, you might want to try a mash-up:
if you combine text from two or more books, the random
text you generate will blend the vocabulary and phrases from
the sources in interesting ways.
</em><a id="hevea_default1182"></a></li></ol><p><em>Credit: This case study is based on an example from Kernighan and
Pike, </em>The Practice of Programming<em>, Addison-Wesley, 1999.</em></p></div><p>You should attempt this exercise before you go on; then you can can
download my solution from <a href="http://thinkpython2.com/code/markov.py"><span class="c004">http://thinkpython2.com/code/markov.py</span></a>.
You will also need <a href="http://thinkpython2.com/code/emma.txt"><span class="c004">http://thinkpython2.com/code/emma.txt</span></a>.</p>
<h2 class="section" id="sec160">13.9&#XA0;&#XA0;Data structures</h2>
<p>
<a id="hevea_default1183"></a></p><p>Using Markov analysis to generate random text is fun, but there is
also a point to this exercise: data structure selection. In your
solution to the previous exercises, you had to choose:</p><ul class="itemize"><li class="li-itemize">How to represent the prefixes.</li><li class="li-itemize">How to represent the collection of possible suffixes.</li><li class="li-itemize">How to represent the mapping from each prefix to
the collection of possible suffixes.</li></ul><p>The last one is easy: a dictionary is the obvious choice
for a mapping from keys to corresponding values.</p><p>For the prefixes, the most obvious options are string,
list of strings, or tuple of strings.</p><p>For the suffixes,
one option is a list; another is a histogram (dictionary).
<a id="hevea_default1184"></a></p><p>How should you choose? The first step is to think about
the operations you will need to implement for each data structure.
For the prefixes, we need to be able to remove words from
the beginning and add to the end. For example, if the current
prefix is &#X201C;Half a&#X201D;, and the next word is &#X201C;bee&#X201D;, you need
to be able to form the next prefix, &#X201C;a bee&#X201D;.
<a id="hevea_default1185"></a></p><p>Your first choice might be a list, since it is easy to add
and remove elements, but we also need to be able to use the
prefixes as keys in a dictionary, so that rules out lists.
With tuples, you can&#X2019;t append or remove, but you can use
the addition operator to form a new tuple:</p><pre class="verbatim">def shift(prefix, word):
    return prefix[1:] + (word,)
</pre><p><span class="c004">shift</span> takes a tuple of words, <span class="c004">prefix</span>, and a string, 
<span class="c004">word</span>, and forms a new tuple that has all the words
in <span class="c004">prefix</span> except the first, and <span class="c004">word</span> added to
the end.</p><p>For the collection of suffixes, the operations we need to
perform include adding a new suffix (or increasing the frequency
of an existing one), and choosing a random suffix.</p><p>Adding a new suffix is equally easy for the list implementation
or the histogram. Choosing a random element from a list
is easy; choosing from a histogram is harder to do
efficiently (see Exercise&#XA0;<a href="thinkpython2014.html#randhist">7</a>).</p><p>So far we have been talking mostly about ease of implementation,
but there are other factors to consider in choosing data structures.
One is run time. Sometimes there is a theoretical reason to expect
one data structure to be faster than other; for example, I mentioned
that the <span class="c004">in</span> operator is faster for dictionaries than for lists,
at least when the number of elements is large.</p><p>But often you don&#X2019;t know ahead of time which implementation will
be faster. One option is to implement both of them and see which
is better. This approach is called <span class="c010">benchmarking</span>. A practical
alternative is to choose the data structure that is
easiest to implement, and then see if it is fast enough for the
intended application. If so, there is no need to go on. If not,
there are tools, like the <span class="c004">profile</span> module, that can identify
the places in a program that take the most time.
<a id="hevea_default1186"></a>
<a id="hevea_default1187"></a>
<a id="hevea_default1188"></a></p><p>The other factor to consider is storage space. For example, using a
histogram for the collection of suffixes might take less space because
you only have to store each word once, no matter how many times it
appears in the text. In some cases, saving space can also make your
program run faster, and in the extreme, your program might not run at
all if you run out of memory. But for many applications, space is a
secondary consideration after run time.</p><p>One final thought: in this discussion, I have implied that
we should use one data structure for both analysis and generation. But
since these are separate phases, it would also be possible to use one
structure for analysis and then convert to another structure for
generation. This would be a net win if the time saved during
generation exceeded the time spent in conversion.</p>
<h2 class="section" id="sec161">13.10&#XA0;&#XA0;Debugging</h2>
<p>
<a id="hevea_default1189"></a></p><p>When you are debugging a program, and especially if you are
working on a hard bug, there are five things to try:</p><dl class="description"><dt class="dt-description"><span class="c010">Reading:</span></dt><dd class="dd-description"> Examine your code, read it back to yourself, and
check that it says what you meant to say.</dd><dt class="dt-description"><span class="c010">Running:</span></dt><dd class="dd-description"> Experiment by making changes and running different
versions. Often if you display the right thing at the right place
in the program, the problem becomes obvious, but sometimes you have to
build scaffolding.</dd><dt class="dt-description"><span class="c010">Ruminating:</span></dt><dd class="dd-description"> Take some time to think! What kind of error
is it: syntax, runtime, or semantic? What information can you get from
the error messages, or from the output of the program? What kind of
error could cause the problem you&#X2019;re seeing? What did you change
last, before the problem appeared?</dd><dt class="dt-description"><span class="c010">Rubberducking:</span></dt><dd class="dd-description"> If you explain the problem to someone else, you
sometimes find the answer before you finish asking the question.
Often you don&#X2019;t need the other person; you could just talk to a rubber
duck. And that&#X2019;s the origin of the well-known strategy called <span class="c010">rubber duck debugging</span>. I am not making this up; see
<a href="https://en.wikipedia.org/wiki/Rubber_duck_debugging"><span class="c004">https://en.wikipedia.org/wiki/Rubber_duck_debugging</span></a>.</dd><dt class="dt-description"><span class="c010">Retreating:</span></dt><dd class="dd-description"> At some point, the best thing to do is back
off, undoing recent changes, until you get back to a program that
works and that you understand. Then you can start rebuilding.</dd></dl><p>Beginning programmers sometimes get stuck on one of these activities
and forget the others. Each activity comes with its own failure
mode.
<a id="hevea_default1190"></a></p><p>For example, reading your code might help if the problem is a
typographical error, but not if the problem is a conceptual
misunderstanding. If you don&#X2019;t understand what your program does, you
can read it 100 times and never see the error, because the error is in
your head.
<a id="hevea_default1191"></a></p><p>Running experiments can help, especially if you run small, simple
tests. But if you run experiments without thinking or reading your
code, you might fall into a pattern I call &#X201C;random walk programming&#X201D;,
which is the process of making random changes until the program
does the right thing. Needless to say, random walk programming
can take a long time.
<a id="hevea_default1192"></a>
<a id="hevea_default1193"></a></p><p>You have to take time to think. Debugging is like an
experimental science. You should have at least one hypothesis about
what the problem is. If there are two or more possibilities, try to
think of a test that would eliminate one of them.</p><p>But even the best debugging techniques will fail if there are too many
errors, or if the code you are trying to fix is too big and
complicated. Sometimes the best option is to retreat, simplifying the
program until you get to something that works and that you
understand.</p><p>Beginning programmers are often reluctant to retreat because
they can&#X2019;t stand to delete a line of code (even if it&#X2019;s wrong).
If it makes you feel better, copy your program into another file
before you start stripping it down. Then you can copy the pieces
back one at a time.</p><p>Finding a hard bug requires reading, running, ruminating, and
sometimes retreating. If you get stuck on one of these activities,
try the others.</p>
<h2 class="section" id="sec162">13.11&#XA0;&#XA0;Glossary</h2>
<dl class="description"><dt class="dt-description"><span class="c010">deterministic:</span></dt><dd class="dd-description"> Pertaining to a program that does the same
thing each time it runs, given the same inputs.
<a id="hevea_default1194"></a></dd><dt class="dt-description"><span class="c010">pseudorandom:</span></dt><dd class="dd-description"> Pertaining to a sequence of numbers that appears
to be random, but is generated by a deterministic program.
<a id="hevea_default1195"></a></dd><dt class="dt-description"><span class="c010">default value:</span></dt><dd class="dd-description"> The value given to an optional parameter if no
argument is provided.
<a id="hevea_default1196"></a></dd><dt class="dt-description"><span class="c010">override:</span></dt><dd class="dd-description"> To replace a default value with an argument.
<a id="hevea_default1197"></a></dd><dt class="dt-description"><span class="c010">benchmarking:</span></dt><dd class="dd-description"> The process of choosing between data structures
by implementing alternatives and testing them on a sample of the
possible inputs. 
<a id="hevea_default1198"></a></dd><dt class="dt-description"><span class="c010">rubber duck debugging:</span></dt><dd class="dd-description"> Debugging by explaining your problem
to an inanimate object such as a rubber duck. Articulating the
problem can help you solve it, even if the rubber duck doesn&#X2019;t know
Python. 
<a id="hevea_default1199"></a>
<a id="hevea_default1200"></a></dd></dl>
<h2 class="section" id="sec163">13.12&#XA0;&#XA0;Exercises</h2>
<div class="theorem"><span class="c010">Exercise&#XA0;9</span>&#XA0;&#XA0;
<a id="hevea_default1201"></a>
<a id="hevea_default1202"></a>
<a id="hevea_default1203"></a><p><em>The &#X201C;rank&#X201D; of a word is its position in a list of words
sorted by frequency: the most common word has rank 1, the
second most common has rank 2, etc.</em></p><p><em>Zipf&#X2019;s law describes a relationship between the ranks and frequencies
of words in natural languages
(</em><a href="http://en.wikipedia.org/wiki/Zipf's_law"><em><span class="c004">http://en.wikipedia.org/wiki/Zipf's_law</span></em></a><em>). Specifically, it
predicts that the frequency, </em><span class="c009">f</span><em>, of the word with rank </em><span class="c009">r</span><em> is:</em></p><table class="display dcenter"><tr class="c017"><td class="dcell"><span class="c009">f</span>&#XA0;=&#XA0;<span class="c009">c</span>&#XA0;<span class="c009">r</span><sup>&#X2212;<span class="c009">s</span></sup>&#XA0;</td></tr>
</table><p><em>
where </em><span class="c009">s</span><em> and </em><span class="c009">c</span><em> are parameters that depend on the language and the
text. If you take the logarithm of both sides of this equation, you
get:
</em><a id="hevea_default1204"></a></p><table class="display dcenter"><tr class="c017"><td class="dcell">log<span class="c009">f</span>&#XA0;=&#XA0;log<span class="c009">c</span>&#XA0;&#X2212;&#XA0;<span class="c009">s</span>&#XA0;log<span class="c009">r</span>&#XA0;</td></tr>
</table><p><em>
So if you plot log </em><span class="c009">f</span><em> versus log </em><span class="c009">r</span><em>, you should get
a straight line with slope </em>&#X2212;<span class="c009">s</span><em> and intercept log </em><span class="c009">c</span><em>.</em></p><p><em>Write a program that reads a text from a file, counts
word frequencies, and prints one line
for each word, in descending order of frequency, with
log </em><span class="c009">f</span><em> and log </em><span class="c009">r</span><em>. Use the graphing program of your
choice to plot the results and check whether they form
a straight line. Can you estimate the value of </em><span class="c009">s</span><em>?</em></p><p><em>Solution: </em><a href="http://thinkpython2.com/code/zipf.py"><span class="c004"><em>http://thinkpython2.com/code/zipf.py</em></span></a><em>.
To run my solution, you need the plotting module <span class="c004">matplotlib</span>.
If you installed Anaconda, you already have <span class="c004">matplotlib</span>;
otherwise you might have to install it.
</em><a id="hevea_default1205"></a></p></div>
<p>
<a href="http://amzn.to/1VUYQUU">Buy this book at Amazon.com</a>

</td>

<td width=130 valign="top">

<p>
<h4>Are you using one of our books in a class?</h4>  We'd like to know
about it.  Please consider filling out <a href="http://spreadsheets.google.com/viewform?formkey=dC0tNUZkMjBEdXVoRGljNm9FRmlTMHc6MA" onClick="javascript: pageTracker._trackPageview('/outbound/survey');">this short survey</a>.

<p>
<br>

<p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491938455/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491938455&linkCode=as2&tag=greenteapre01-20&linkId=2JJH4SWCAVVYSQHO">Think DSP</a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491938455" width="1" height="1" border="0" alt="">

<p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491938455/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491938455&linkCode=as2&tag=greenteapre01-20&linkId=CTV7PDT7E5EGGJUM"><img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=1491938455&Format=_SL160_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=greenteapre01-20"></a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491938455" width="1" height="1" border="0" alt="">

<p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491929561/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491929561&linkCode=as2&tag=greenteapre01-20&linkId=ZY6MAYM33ZTNSCNZ">Think Java</a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491929561" width="1" height="1" border="0" alt="">

<p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491929561/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491929561&linkCode=as2&tag=greenteapre01-20&linkId=PT77ANWARUNNU3UK"><img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=1491929561&Format=_SL160_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=greenteapre01-20"></a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491929561" width="1" height="1" border="0" alt="">

<p>
<a href="http://www.amazon.com/gp/product/1449370780/ref=as_li_qf_sp_asin_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1449370780&linkCode=as2&tag=greenteapre01-20">Think Bayes</a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1449370780" width="1" height="1" border="0" alt="">

<p>
<a href="http://www.amazon.com/gp/product/1449370780/ref=as_li_qf_sp_asin_il?ie=UTF8&camp=1789&creative=9325&creativeASIN=1449370780&linkCode=as2&tag=greenteapre01-20"><img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1449370780&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=greenteapre01-20"></a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1449370780" width="1" height="1" border="0" alt="">

<p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491939362/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491939362&linkCode=as2&tag=greenteapre01-20&linkId=FJKSQ3IHEMY2F2VA">Think Python 2e</a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491939362" width="1" height="1" border="0" alt="">


<p>
<a rel="nofollow" href="http://www.amazon.com/gp/product/1491939362/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491939362&linkCode=as2&tag=greenteapre01-20&linkId=ZZ454DLQ3IXDHNHX"><img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&ASIN=1491939362&Format=_SL160_&ID=AsinImage&MarketPlace=US&ServiceVersion=20070822&WS=1&tag=greenteapre01-20"></a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491939362" width="1" height="1" border="0" alt="">

<p>
<a href="http://www.amazon.com/gp/product/1491907339/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491907339&linkCode=as2&tag=greenteapre01-20&linkId=O7WYM6H6YBYUFNWU">Think Stats 2e</a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491907339" width="1" height="1" border="0" alt="">

<p>
<a href="http://www.amazon.com/gp/product/1491907339/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1491907339&linkCode=as2&tag=greenteapre01-20&linkId=JVSYKQHYSUIEYRHL"><img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1491907339&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=greenteapre01-20"></a><img class="c003" src="http://ir-na.amazon-adsystem.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1491907339" width="1" height="1" border="0" alt="">

<p>
<a href="http://www.amazon.com/gp/product/1449314635/ref=as_li_tf_tl?ie=UTF8&tag=greenteapre01-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=1449314635">Think Complexity</a><img class="c003" src="http://www.assoc-amazon.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1449314635" width="1" height="1" border="0" alt="">

<p>
<a href="http://www.amazon.com/gp/product/1449314635/ref=as_li_tf_il?ie=UTF8&camp=1789&creative=9325&creativeASIN=1449314635&linkCode=as2&tag=greenteapre01-20"><img border="0" src="http://ws-na.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;ASIN=1449314635&amp;Format=_SL160_&amp;ID=AsinImage&amp;MarketPlace=US&amp;ServiceVersion=20070822&amp;WS=1&amp;tag=greenteapre01-20"></a><img class="c003" src="http://www.assoc-amazon.com/e/ir?t=greenteapre01-20&l=as2&o=1&a=1449314635" width="1" height="1" border="0" alt="">


</td>
</tr>
</table>
<hr>
<a href="thinkpython2013.html"><img src="back.png" ALT="Previous"></a>
<a href="index.html.1"><img src="up.png" ALT="Up"></a>
<a href="thinkpython2015.html"><img src="next.png" ALT="Next"></a>
</body>
</html>
